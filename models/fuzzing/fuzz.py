'''This file is for generating new test cases. (RQ3)'''

import nltk
nltk.download('punkt')
import torch
from transformers import BertTokenizer, BertForMaskedLM
from torch.nn import functional as F


def get_nouns_list(text):
    '''
    This function returns a list of nouns in the input text.
    Return a list: [(position, word)]
    '''
    tokens = nltk.word_tokenize(text) # tokenize the text
    tagged = nltk.pos_tag(tokens) # tag the tokens
    # get position of nouns
    nouns = [(i, word) for i, (word, tag) in enumerate(tagged) if tag == 'NN' or tag == 'NNS']
    return nouns

def get_substitues_from_BERT(text, position, tokenizer):
    '''
    Given a text and a position to be masked, this function returns a list of substitues generated by the "masked language prediction" function of BERT.
    '''
    tokens = text.split(" ")
    tokens[position] = tokenizer.mask_token # replace the token with the mask token
    text = " ".join(tokens) # reconstruct the text

    input = tokenizer.encode(text, return_tensors="pt") # encode the text

    output = model(input) # get the output of the model
    logits = output.logits # get the logits

    softmax = F.softmax(logits, dim=-1) # get the softmax of the logits
    mask_word = softmax[0, position + 1, :] 
    # Notes: Here we need 



    # get top 10
    top_10 = torch.topk(mask_word, 10)[1]
    substitues = []
    for token in top_10:
        token = token.item()
        substitues.append((tokenizer.decode([token])))
    
    return substitues

if __name__=='__main__':
    # obtain the list of nouns
    text = "Perhaps she had already met her fate a little deeper in the forest"
    nouns = get_nouns_list(text)
    print(nouns)

    # get substitues from BERT
    model_name = "bert-base-uncased"
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertForMaskedLM.from_pretrained(model_name)
    for noun in nouns:
        position = noun[0]
        if position == len(text.split()) - 1:
            # skip the last word, as typically it will be predicted as ',.?!'
            continue
        word = noun[1]
        print("word:", word)
        substitues = get_substitues_from_BERT(text, position, tokenizer)
        print(substitues)



