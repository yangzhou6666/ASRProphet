{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_error_model_name = {\n",
    "    \"random\" : \"RND\",\n",
    "    \"error_model_triphone_rich\" : \"TR\",\n",
    "    \"error_model_pure_diversity\" : \"PD\",\n",
    "    \"error_model_without_diversity_enhancing\" : \"IC-WDE\",\n",
    "    \"error_model\" : \"IC\",\n",
    "    \"asrevolve_error_model_real\" : \"ASR-EV\",\n",
    "    \"word_error_predictor_real/no_word_enhance\" : \"NWE\",\n",
    "    \"word_error_predictor_real/word_enhance\": \"WE\"\n",
    "}\n",
    "\n",
    "shorten_finetuned_model_name = {\n",
    "    \"random\": \"RND\",\n",
    "    \"triphone_rich\": \"TR\",\n",
    "    \"pure_diversity\": \"PD\",\n",
    "    \"icassp_without_diversity_enhancing_real_mix\": \"IC-WDE\",\n",
    "    \"icassp_real_mix\": \"IC\",\n",
    "    \"asrevolve_error_model_real\": \"ASR-EV\",\n",
    "    \"word_error_real_mix/no_word_enhance\": \"NWE\",\n",
    "    \"word_error_real_mix/word_enhance\": \"WE\"\n",
    "}\n",
    "\n",
    "def shorten_em_name(tools):\n",
    "    return [shorten_error_model_name[tool] for tool in tools]\n",
    "\n",
    "def shorten_ft_name(tools) :\n",
    "    return [shorten_finetuned_model_name[tool] for tool in tools]\n",
    "\n",
    "tool_short_names = [\"RND\", \"TR\", \"PD\", \"IC-WDE\", \"IC\", \"ASR-EV\", \"NWE\", \"WE\"]\n",
    "\n",
    "finetuned_model_tool_names = [\"random\", \"triphone_rich\", \"pure_diversity\", \"icassp_without_diversity_enhancing_real_mix\", \"icassp_real_mix\",\n",
    "         \"asrevolve_error_model_real\", \"word_error_real_mix/no_word_enhance\", \"word_error_real_mix/word_enhance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The relative improvement of WER after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/RQ2.json', 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "asrs = [\"quartznet\", \"hubert\", \"wav2vec-base\"]\n",
    "datasets = [\"YBAA\", \"ZHAA\", \"ASI\", \"TNI\", \"NCC\",\n",
    "            \"TXHC\", \"EBVS\", \"ERMS\", \"YDCK\", \"YKWK\", \"THV\", \"TLV\"]\n",
    "tools = [\"random\", \"triphone_rich\", \"pure_diversity\", \"icassp_without_diversity_enhancing_real_mix\", \"icassp_real_mix\",\n",
    "         \"asrevolve_error_model_real\", \"word_error_real_mix/no_word_enhance\", \"word_error_real_mix/word_enhance\"]\n",
    "\n",
    "finetuned_model_performance_on_test_set = {}\n",
    "for asr in asrs:\n",
    "    finetuned_model_performance_on_test_set[asr] = {}\n",
    "    for dataset in datasets:\n",
    "        finetuned_model_performance_on_test_set[asr][dataset] = {}\n",
    "        for tool in tools:\n",
    "            finetuned_model_performance_on_test_set[asr][dataset][shorten_finetuned_model_name[tool]] = pd.read_csv(\n",
    "                data[asr][dataset][tool])\n",
    "\n",
    "# finetuned_model_performance_on_test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/original.json', 'r') as f:\n",
    "  original_data = json.load(f)\n",
    "\n",
    "original_model_performance_on_test_set = {}\n",
    "\n",
    "for asr in asrs:\n",
    "    original_model_performance_on_test_set[asr] = {}\n",
    "    for dataset in datasets:\n",
    "        original_model_performance_on_test_set[asr][dataset] = original_data[asr][dataset][\"test\"][\"wer\"]\n",
    "\n",
    "# original_model_performance_on_test_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_improvement_of_finetuned_model = {}\n",
    "for asr in asrs:\n",
    "    relative_improvement_of_finetuned_model[asr] = {}\n",
    "    for dataset in datasets:\n",
    "        relative_improvement_of_finetuned_model[asr][dataset] = {}\n",
    "        for tool in shorten_ft_name(tools):\n",
    "            relative_improvement_of_finetuned_model[asr][dataset][tool] = {}\n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\", \"WER_Avg\"]:\n",
    "                relative_improvement_of_finetuned_model[asr][dataset][tool][metric] = (\n",
    "                    (original_model_performance_on_test_set[asr][dataset] - finetuned_model_performance_on_test_set[asr][dataset][tool][metric]) / original_model_performance_on_test_set[asr][dataset]).to_list()\n",
    "\n",
    "# relative_improvement_of_finetuned_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(fpath, printed, significant_count, non_significant_count):\n",
    "    os.makedirs(os.path.dirname(fpath), exist_ok=True)\n",
    "    with open(fpath, 'w') as f:\n",
    "        f.write(f\"Significant: \\t\\t{significant_count}\\n\")\n",
    "        f.write(f\"Non-significant: \\t{non_significant_count}\\n\")\n",
    "        f.write(\n",
    "            f\"Total: \\t\\t\\t\\t{significant_count + non_significant_count}\\n\")\n",
    "        f.write(\n",
    "            f\"Percentage: \\t\\t{100*significant_count / (significant_count + non_significant_count):.2f}%\\n\\n\")\n",
    "        for line in printed:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "CONFIDENCE_LEVEL = 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Correlation between the original model's WER on the selected samples and the relative improvement of WER after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/RQ1.json', 'r') as f:\n",
    "  rq1_data = json.load(f)\n",
    "\n",
    "\n",
    "original_model_performance_on_selected_samples = {}\n",
    "\n",
    "asrs = [\"quartznet\", \"hubert\", \"wav2vec-base\"]\n",
    "datasets = [\"YBAA\", \"ZHAA\", \"ASI\", \"TNI\", \"NCC\",\n",
    "            \"TXHC\", \"EBVS\", \"ERMS\", \"YDCK\", \"YKWK\", \"THV\", \"TLV\"]\n",
    "tools = [\"random\", \"error_model_triphone_rich\", \"error_model_pure_diversity\", \"error_model_without_diversity_enhancing\", \"error_model\",\n",
    "         \"asrevolve_error_model_real\", \"word_error_predictor_real/no_word_enhance\", \"word_error_predictor_real/word_enhance\"]\n",
    "\n",
    "original_model_performance_on_selected_samples = {}\n",
    "for asr in asrs:\n",
    "    original_model_performance_on_selected_samples[asr] = {}\n",
    "    for dataset in datasets:\n",
    "        original_model_performance_on_selected_samples[asr][dataset] = {}\n",
    "        for tool in tools:\n",
    "            original_model_performance_on_selected_samples[asr][dataset][shorten_error_model_name[tool]] = {}\n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\", \"WER_Avg\"]:\n",
    "                original_model_performance_on_selected_samples[asr][dataset][shorten_error_model_name[tool]][metric] = pd.read_csv(\n",
    "                  rq1_data[asr][dataset][tool])[metric].tolist()\n",
    "\n",
    "# original_model_performance_on_selected_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.021986090955998173, pvalue=0.19628736520635923)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1 = []\n",
    "arr_2 = []\n",
    "\n",
    "for asr in asrs:\n",
    "    for dataset in datasets:\n",
    "        for tool in tool_short_names:\n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "                arr_1 += original_model_performance_on_selected_samples[asr][dataset][tool][metric]\n",
    "                arr_2 += relative_improvement_of_finetuned_model[asr][dataset][tool][metric]\n",
    "\n",
    "assert len(arr_1) == len(arr_2)\n",
    "scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.942857142857143, pvalue=0.004804664723032055)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1 = [-3.49, 10.18, 8.98, 6.62, 27.33, 21.52]\n",
    "arr_2 = [4.0375, 4.3025, 4.2475, 4.2, 4.3275, 4.4175]\n",
    "scipy.stats.spearmanr(arr_1, arr_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset:  YBAA\n",
      "ASR:  quartznet\n",
      "Spearman's corr coeff:\t  0.9999999999999999\n",
      "p-value:\t\t  1.4042654220543672e-24\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    for asr in asrs:\n",
    "        arr_1 = []\n",
    "        arr_2 = []\n",
    "        # for tool in [\"RND\", \"TR\", \"PD\", \"IC-WDE\", \"IC\", \"ASR-EV\", \"NWE\", \"WE\"]:\n",
    "        # for tool in [\"PD\", \"IC-WDE\", \"IC\", \"ASR-EV\", \"NWE\", \"WE\"]:\n",
    "        for tool in [\"PD\", \"IC-WDE\", \"IC\", \"ASR-EV\", \"NWE\"]:\n",
    "            curr_arr_1 = []\n",
    "            curr_arr_2 = []\n",
    "            \n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "                curr_arr_1 += original_model_performance_on_selected_samples[asr][dataset][tool][metric]\n",
    "                curr_arr_2 += relative_improvement_of_finetuned_model[asr][dataset][tool][metric]\n",
    "            \n",
    "            arr_1.append(np.mean(curr_arr_1))\n",
    "            arr_2.append(np.mean(curr_arr_2))\n",
    "\n",
    "        assert len(arr_1) == len(arr_2)\n",
    "        # print(\"Len arr 1: \", len(arr_1))\n",
    "\n",
    "        correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "        print()\n",
    "        print(\"Dataset: \", dataset)\n",
    "        print(\"ASR: \", asr)\n",
    "        print(\"Spearman's corr coeff:\\t \", correlation_coefficient)\n",
    "        print(\"p-value:\\t\\t \", p_value)\n",
    "\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset:  YBAA\n",
      "ASR:  quartznet\n",
      "Spearman's corr coeff:\t  0.38869565217391305\n",
      "p-value:\t\t  0.060498404649825734\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    for asr in asrs:\n",
    "        arr_1 = []\n",
    "        arr_2 = []\n",
    "        for tool in tool_short_names:\n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "\n",
    "                curr_arr_1 = original_model_performance_on_selected_samples[\n",
    "                    asr][dataset][tool][metric]\n",
    "                arr_1.append(np.mean(curr_arr_1))\n",
    "                curr_arr_2 = relative_improvement_of_finetuned_model[asr][dataset][tool][metric]\n",
    "                arr_2.append(np.mean(curr_arr_2))\n",
    "\n",
    "        assert len(arr_1) == len(arr_2)\n",
    "\n",
    "        correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "        print()\n",
    "        print(\"Dataset: \", dataset)\n",
    "        print(\"ASR: \", asr)\n",
    "        print(\"Spearman's corr coeff:\\t \", correlation_coefficient)\n",
    "        print(\"p-value:\\t\\t \", p_value)\n",
    "\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Correlation between \"the distance of triphone rich distribution and ideal distribution on the selected samples\" and the relative improvement of WER after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/triphone_rich.json', 'r') as f:\n",
    "  triphone_rich_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spearman's corr coeff:\t  0.3096296252398027\n",
      "p-value:\t\t  4.728069257623937e-11\n"
     ]
    }
   ],
   "source": [
    "## without any grouping mechanism\n",
    "\n",
    "arr_1 = []\n",
    "arr_2 = []\n",
    "\n",
    "for asr in asrs:\n",
    "    for dataset in datasets:\n",
    "        tool = \"error_model_triphone_rich\"\n",
    "        for seed in [\"1\", \"2\", \"3\"] :\n",
    "            arr_1 += triphone_rich_data[asr][dataset][seed]\n",
    "        for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "            arr_2 += relative_improvement_of_finetuned_model[asr][dataset][shorten_error_model_name[tool]][metric]\n",
    "\n",
    "assert len(arr_1) == len(arr_2)\n",
    "\n",
    "correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "print()\n",
    "print(\"Spearman's corr coeff:\\t \", correlation_coefficient)\n",
    "print(\"p-value:\\t\\t \", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset:  YBAA\n",
      "Spearman's corr coeff:\t  0.29872252445264824\n",
      "p-value:\t\t  0.07677066890825572\n",
      "\n",
      "Dataset:  ZHAA\n",
      "Spearman's corr coeff:\t  0.39171008070249985\n",
      "p-value:\t\t  0.018147182140365984\n",
      "\n",
      "Dataset:  ASI\n",
      "Spearman's corr coeff:\t  0.36745807989066254\n",
      "p-value:\t\t  0.02747414148369915\n",
      "\n",
      "Dataset:  TNI\n",
      "Spearman's corr coeff:\t  -0.032172703215137745\n",
      "p-value:\t\t  0.8522317119652019\n",
      "\n",
      "Dataset:  NCC\n",
      "Spearman's corr coeff:\t  0.6248733893766553\n",
      "p-value:\t\t  4.623396426138484e-05\n",
      "\n",
      "Dataset:  TXHC\n",
      "Spearman's corr coeff:\t  0.427992415964119\n",
      "p-value:\t\t  0.009215235980734586\n",
      "\n",
      "Dataset:  EBVS\n",
      "Spearman's corr coeff:\t  0.3130928912099224\n",
      "p-value:\t\t  0.06298250889255443\n",
      "\n",
      "Dataset:  ERMS\n",
      "Spearman's corr coeff:\t  0.21620999260824883\n",
      "p-value:\t\t  0.20532655747387657\n",
      "\n",
      "Dataset:  YDCK\n",
      "Spearman's corr coeff:\t  0.4356320174220398\n",
      "p-value:\t\t  0.007915519401666004\n",
      "\n",
      "Dataset:  YKWK\n",
      "Spearman's corr coeff:\t  0.15354817534862975\n",
      "p-value:\t\t  0.37127176401256157\n",
      "\n",
      "Dataset:  THV\n",
      "Spearman's corr coeff:\t  0.5276364267396184\n",
      "p-value:\t\t  0.0009430449355650311\n",
      "\n",
      "Dataset:  TLV\n",
      "Spearman's corr coeff:\t  0.455879704606125\n",
      "p-value:\t\t  0.005202186851672289\n"
     ]
    }
   ],
   "source": [
    "## grouping by dataset\n",
    "\n",
    "for dataset in datasets:\n",
    "    arr_1 = []\n",
    "    arr_2 = []\n",
    "    for asr in asrs:\n",
    "        tool = \"error_model_triphone_rich\"\n",
    "        for seed in [\"1\", \"2\", \"3\"]:\n",
    "            arr_1 += triphone_rich_data[asr][dataset][seed]\n",
    "        for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "            arr_2 += relative_improvement_of_finetuned_model[asr][dataset][shorten_error_model_name[tool]][metric]\n",
    "\n",
    "    assert len(arr_1) == len(arr_2)\n",
    "\n",
    "    correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "    print()\n",
    "    print(\"Dataset: \", dataset)\n",
    "    print(\"Spearman's corr coeff:\\t \", correlation_coefficient)\n",
    "    print(\"p-value:\\t\\t \", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Correlation between the number of test cases on the selected samples and the relative improvement of WER after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/number_of_test_cases.json', 'r') as f:\n",
    "  number_of_test_cases = json.load(f)\n",
    "\n",
    "tools = [\"random\", \"error_model_triphone_rich\", \"error_model_pure_diversity\", \"error_model_without_diversity_enhancing\", \"error_model\",\n",
    "         \"asrevolve_error_model_real\", \"word_error_predictor_real/no_word_enhance\", \"word_error_predictor_real/word_enhance\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## without any grouping mechanism\n",
    "\n",
    "printed = []\n",
    "significant_count = 0\n",
    "non_significant_count = 0\n",
    "\n",
    "\n",
    "arr_1 = []\n",
    "arr_2 = []\n",
    "for dataset in datasets:\n",
    "    for asr in asrs:\n",
    "        for tool_short_name, tool in zip(tool_short_names, tools):\n",
    "          for seed in [\"1\", \"2\", \"3\"]:\n",
    "              arr_1 += number_of_test_cases[asr][dataset][tool][seed]\n",
    "          for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "              arr_2 += relative_improvement_of_finetuned_model[asr][dataset][tool_short_name][metric]\n",
    "\n",
    "assert len(arr_1) == len(arr_2)\n",
    "correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "\n",
    "printed.append(f\"Corr coef:\\t{correlation_coefficient}\")\n",
    "printed.append(f\"p-value:\\t{p_value}\")\n",
    "if p_value < CONFIDENCE_LEVEL:\n",
    "    printed.append(f\"SIGNIFICANT\")\n",
    "    significant_count += 1\n",
    "\n",
    "else:\n",
    "    non_significant_count += 1\n",
    "    printed.append(f\"NO\")\n",
    "\n",
    "\n",
    "fpath = \"result/analyze/5/number_of_test_cases_correlation_without_any_grouping.txt\"\n",
    "save_to_file(fpath, printed, significant_count, non_significant_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by dataset\n",
    "\n",
    "printed = []\n",
    "significant_count = 0\n",
    "non_significant_count = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    arr_1 = []\n",
    "    arr_2 = []\n",
    "    for asr in asrs:\n",
    "        for tool_short_name, tool in zip(tool_short_names, tools):\n",
    "          for seed in [\"1\", \"2\", \"3\"]:\n",
    "              arr_1 += number_of_test_cases[asr][dataset][tool][seed]\n",
    "          for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "              arr_2 += relative_improvement_of_finetuned_model[asr][dataset][tool_short_name][metric]\n",
    "\n",
    "    assert len(arr_1) == len(arr_2)\n",
    "    correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "    printed.append(f\"Dataset: {dataset}\")\n",
    "    printed.append(f\"Corr coef:\\t{correlation_coefficient}\")\n",
    "    printed.append(f\"p-value:\\t{p_value}\")\n",
    "    if p_value < CONFIDENCE_LEVEL:\n",
    "        printed.append(f\"SIGNIFICANT\")\n",
    "        significant_count += 1\n",
    "    else:\n",
    "        printed.append(f\"NO\")\n",
    "        non_significant_count += 1\n",
    "    printed.append(\"\")\n",
    "\n",
    "\n",
    "fpath = \"result/analyze/5/number_of_test_cases_correlation_group_by_dataset.txt\"\n",
    "save_to_file(fpath, printed, significant_count, non_significant_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by dataset and ASR\n",
    "\n",
    "printed = []\n",
    "significant_count = 0\n",
    "non_significant_count = 0\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for asr in asrs:\n",
    "        arr_1 = []\n",
    "        arr_2 = []\n",
    "        for tool_short_name, tool in zip(tool_short_names, tools):\n",
    "          for seed in [\"1\", \"2\", \"3\"]:\n",
    "              arr_1 += number_of_test_cases[asr][dataset][tool][seed]\n",
    "          for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "              arr_2 += relative_improvement_of_finetuned_model[asr][dataset][tool_short_name][metric]\n",
    "\n",
    "        assert len(arr_1) == len(arr_2)\n",
    "        correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "        printed.append(f\"Dataset: {dataset}\")\n",
    "        printed.append(f\"ASR: {asr}\")\n",
    "        printed.append(f\"Corr coef:\\t{correlation_coefficient}\")\n",
    "        printed.append(f\"p-value:\\t{p_value}\")\n",
    "        if p_value < CONFIDENCE_LEVEL:\n",
    "            printed.append(f\"SIGNIFICANT\")\n",
    "            significant_count += 1\n",
    "\n",
    "        else:\n",
    "            printed.append(f\"NO\")\n",
    "            non_significant_count += 1\n",
    "        printed.append(\"\")\n",
    "\n",
    "\n",
    "fpath = \"result/analyze/5/number_of_test_cases_correlation_group_by_dataset_and_asr.txt\"\n",
    "save_to_file(fpath, printed, significant_count, non_significant_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by dataset and ASR then averaging budget\n",
    "\n",
    "printed = []\n",
    "significant_count = 0\n",
    "non_significant_count = 0\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for asr in asrs:\n",
    "        arr_1 = []\n",
    "        arr_2 = []\n",
    "        for tool_short_name, tool in zip(tool_short_names, tools):\n",
    "            for seed in [\"1\", \"2\", \"3\"]:\n",
    "                curr_arr_1 = number_of_test_cases[asr][dataset][tool][seed]\n",
    "                arr_1.append(np.mean(curr_arr_1))\n",
    "            \n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "                curr_arr_2 = relative_improvement_of_finetuned_model[asr][dataset][tool_short_name][metric]\n",
    "                arr_2.append(np.mean(curr_arr_2))\n",
    "\n",
    "\n",
    "        assert len(arr_1) == len(arr_2)\n",
    "        correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "        printed.append(f\"Dataset: {dataset}\")\n",
    "        printed.append(f\"ASR: {asr}\")\n",
    "        printed.append(f\"Corr coef:\\t{correlation_coefficient}\")\n",
    "        printed.append(f\"p-value:\\t{p_value}\")\n",
    "        if p_value < CONFIDENCE_LEVEL:\n",
    "            printed.append(f\"SIGNIFICANT\")\n",
    "            significant_count += 1\n",
    "\n",
    "        else:\n",
    "            printed.append(f\"NO\")\n",
    "            non_significant_count += 1\n",
    "        printed.append(\"\")\n",
    "\n",
    "\n",
    "fpath = \"result/analyze/5/number_of_test_cases_correlation_group_by_dataset_and_asr_then_averaging_budget.txt\"\n",
    "save_to_file(fpath, printed, significant_count, non_significant_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by dataset and ASR and budget\n",
    "\n",
    "printed = []\n",
    "significant_count = 0\n",
    "non_significant_count = 0\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for asr in asrs:\n",
    "        \n",
    "        temp_1 = {}\n",
    "        temp_2 = {}\n",
    "        \n",
    "        \n",
    "        for tool_short_name, tool in zip(tool_short_names, tools):\n",
    "            for seed in [\"1\", \"2\", \"3\"]:\n",
    "                for budget, val in zip([100, 200, 300, 400], number_of_test_cases[asr][dataset][tool][seed]) :\n",
    "                    if budget not in temp_1:\n",
    "                        temp_1[budget] = []\n",
    "                    temp_1[budget].append(val)\n",
    "                \n",
    "\n",
    "            for metric in [\"WER_Seed1\", \"WER_Seed2\", \"WER_Seed3\"]:\n",
    "                for budget, val in zip([100, 200, 300, 400], relative_improvement_of_finetuned_model[\n",
    "                    asr][dataset][tool_short_name][metric]) :\n",
    "                    if budget not in temp_2:\n",
    "                        temp_2[budget] = []\n",
    "                    temp_2[budget].append(val)\n",
    "        \n",
    "\n",
    "        for budget in [100, 200, 300, 400]:\n",
    "            arr_1 = temp_1[budget]\n",
    "            arr_2 = temp_2[budget]\n",
    "\n",
    "            assert len(arr_1) == len(arr_2)\n",
    "            correlation_coefficient, p_value = scipy.stats.spearmanr(arr_1, arr_2)\n",
    "\n",
    "            printed.append(f\"Dataset: {dataset}\")\n",
    "            printed.append(f\"ASR: {asr}\")\n",
    "            printed.append(f\"Corr coef:\\t{correlation_coefficient}\")\n",
    "            printed.append(f\"p-value:\\t{p_value}\")\n",
    "            if p_value < CONFIDENCE_LEVEL:\n",
    "                printed.append(f\"SIGNIFICANT\")\n",
    "                significant_count += 1\n",
    "\n",
    "            else:\n",
    "                printed.append(f\"NO\")\n",
    "                non_significant_count += 1\n",
    "            printed.append(\"\")\n",
    "\n",
    "\n",
    "fpath = \"result/analyze/5/number_of_test_cases_correlation_group_by_dataset_and_asr_and_budget.txt\"\n",
    "save_to_file(fpath, printed, significant_count, non_significant_count)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
